$schema: "http://json-schema.org/draft-07/schema#"
$id: "tokenization.schema.yaml"
allOf:
  - $ref: "../base.schema.yaml"
  - type: object
    properties:      
      tokenizer:
        type: object
        properties:
          tokenizer_name:
            type: string
            description: "HuggingFace tokenizer name"
          ignore_index:
            type: integer
            default: -100
            description: "Label value to ignore during loss computation (e.g., for masked prompt tokens). Applies to instruction tasks."
          max_sequence_length:
            type: integer
            description: "Maximum sequence length for tokenization (optional, defaults to context_length). Applies to instruction tasks."
          batch_size:
            type: integer
            minimum: 1
            default: 2000
            description: "Batch size for processing datasets. Higher values improve performance but use more memory."
          num_proc:
            type: integer
            minimum: 1
            maximum: 32
            default: 1
            description: "Number of processes for parallel tokenization. Set > 1 for faster processing of large datasets."
          show_progress:
            type: boolean
            default: true
            description: "Whether to show progress bars during tokenization"
        required:
          - tokenizer_name

      dataset:
        type: object
        properties:
          source:
            type: string
            enum: ["huggingface", "local"]
          nameOrPath:
            type: string
            description: "Dataset name for HuggingFace or local path"
          format:
            type: string
            enum: ["dataset", "files", "multilanguage_files"]
          file_config:
            type: object
            properties:
              format:
                type: string
                default: "any"
                enum: ["csv", "txt", "json", "jsonl", "parquet"]
              text_column:
                type: string
              text_key:
                type: string
                description: "For JSON/JSONL files, the key to extract text from when each entry is a dictionary"
              encoding:
                type: string
                default: "utf-8"

          use_txt_as_samples:
            type: boolean
            default: false

          save_raw:
            type: object
            properties:
              enabled:
                type: boolean
              path:
                type: string
        required:
          - source
          - nameOrPath
          - format

      output:
        type: object
        properties:
          path:
            type: string
            description: "Path to save tokenized dataset"
        required:
          - path

      test_size:
        type: number
        minimum: 0
        maximum: 1
        default: null
    
    required:
      - tokenizer
      - dataset
      - output
