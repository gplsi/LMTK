task: "tokenization"
experiment_name: "md_anonymized_llama_3b_tokenization"
verbose_level: 3

tokenizer:
  tokenizer_name: "meta-llama/Llama-3.2-3B"
  context_length: 2048
  overlap: 512
  task: "clm_training"

dataset:
  source: "local"
  nameOrPath: "/workspace/data/dc6"
  format: "files"
  file_config:
    text_key: "text"
    format: "txt"
    encoding: "utf-8"

output:
  path: "/workspace/data/tokenized/dc6-llama-3b"

test_size: 0.9