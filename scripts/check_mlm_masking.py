#!/usr/bin/env python3
import argparse
import json
from pathlib import Path
from statistics import mean


def compute_masking_stats(samples_path: Path, mask_token_id: int = 50264) -> None:
    with samples_path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    ratios = []
    for idx, sample in enumerate(data.get("samples", [])):
        tokenization = sample.get("tokenization", {})
        input_ids = tokenization.get("input_ids", [])
        labels = tokenization.get("labels", [])

        labeled_positions = [i for i, l in enumerate(labels) if l != -100]
        masked_positions = [i for i in labeled_positions if i < len(input_ids) and input_ids[i] == mask_token_id]

        num_labeled = len(labeled_positions)
        num_masked = len(masked_positions)
        ratio = (num_masked / num_labeled) if num_labeled else 0.0
        if num_labeled:
            ratios.append(ratio)

        print(
            f"sample {idx}: labeled={num_labeled}, masked={num_masked}, masked_ratio={ratio:.2f}"
        )

    if ratios:
        print(f"avg_masked_ratio {mean(ratios):.2f}")
    else:
        print("avg_masked_ratio 0.00")


def main() -> None:
    parser = argparse.ArgumentParser(description="Check MLM masking ratios from visualization output")
    parser.add_argument(
        "--json",
        type=str,
        default="/home/gplsi/fabio/experiments/LMTK/LMTK/output/tokenized_visuals/dataset_samples.json",
        help="Path to dataset_samples.json generated by visualize_tokenized_dataset.py",
    )
    parser.add_argument(
        "--mask_token_id",
        type=int,
        default=50264,
        help="Mask token id to check (default: 50264 for RoBERTa)",
    )
    args = parser.parse_args()

    samples_path = Path(args.json)
    if not samples_path.exists():
        raise FileNotFoundError(f"JSON file not found: {samples_path}")

    compute_masking_stats(samples_path, mask_token_id=args.mask_token_id)


if __name__ == "__main__":
    main()



